{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison to DuPLO Model\n",
    "\n",
    "\n",
    "Train models via \n",
    "```bash\n",
    "python train_duplo.py 23classes GAFv2\n",
    "python train_duplo.py 12classes GAFv2\n",
    "python train_duplo.py 23classes BavarianCrops\n",
    "python train_duplo.py 12classes BavarianCrops\n",
    "```\n",
    "executing these scripts require downloading the TUM dataset (via `bash download.sh data`) and the GAF dataset (not public)\n",
    "\n",
    "To reproduce this notebook you can obtain the pretrained models and logs via\n",
    "```\n",
    "cd <repository root>\n",
    "bash download.sh duplo\n",
    "```\n",
    "to `../models/duplo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "sys.path.append(\"../src/models\")\n",
    "\n",
    "from models.duplo import DuPLO\n",
    "import torch\n",
    "from train import prepare_dataset\n",
    "from argparse import Namespace\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import os\n",
    "from datasets.BavarianCrops_Dataset import BavarianCropsDataset\n",
    "from train_duplo import metrics\n",
    "\n",
    "model_root = \"../models/duplo\"\n",
    "\n",
    "def merge(namespaces):\n",
    "    merged = dict()\n",
    "\n",
    "    for n in namespaces:\n",
    "        d = n.__dict__\n",
    "        for k,v in d.items():\n",
    "            merged[k]=v\n",
    "\n",
    "    return Namespace(**merged)\n",
    "\n",
    "TUM_dataset = Namespace(\n",
    "    dataset = \"BavarianCrops\",\n",
    "    trainregions = [\"holl\",\"nowa\",\"krum\"],\n",
    "    testregions = [\"holl\",\"nowa\",\"krum\"],\n",
    "    scheme=\"blocks\",\n",
    "    test_on = \"test\",\n",
    "    train_on = \"trainvalid\",\n",
    "    samplet = 70\n",
    ")\n",
    "\n",
    "GAF_dataset = Namespace(\n",
    "    dataset = \"GAFv2\",\n",
    "    trainregions = [\"holl\",\"nowa\",\"krum\"],\n",
    "    testregions = [\"holl\",\"nowa\",\"krum\"],\n",
    "    features = \"optical\",\n",
    "    scheme=\"blocks\",\n",
    "    test_on=\"test\",\n",
    "    train_on=\"train\",\n",
    "    samplet = 23\n",
    ")\n",
    "\n",
    "def setup(dataset, mode, dataroot=\"../data\", store = '/tmp/'):\n",
    "    \n",
    "    if mode == \"12classes\":\n",
    "        classmapping = os.path.join(dataroot,\"BavarianCrops\",'classmapping12.csv')\n",
    "    elif mode == \"23classes\":\n",
    "        classmapping = os.path.join(dataroot,\"BavarianCrops\",'classmapping23.csv')\n",
    "    \n",
    "    args = Namespace(batchsize=256,\n",
    "                 classmapping=classmapping,\n",
    "                 dataroot=dataroot, dataset=dataset,\n",
    "                 model='duplo',mode=None,\n",
    "                 seed=0, store=store, workers=0)\n",
    "\n",
    "    if dataset == \"BavarianCrops\":\n",
    "        args = merge([args,TUM_dataset])\n",
    "        exp = \"isprs_tum_duplo\"\n",
    "    elif dataset == \"GAFv2\":\n",
    "        args = merge([args,GAF_dataset])\n",
    "        exp = \"isprs_gaf_duplo\"\n",
    "        \n",
    "    traindataloader, testdataloader = prepare_dataset(args)\n",
    "        \n",
    "    input_dim = traindataloader.dataset.datasets[0].ndims\n",
    "    nclasses = len(traindataloader.dataset.datasets[0].classes)\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = DuPLO(input_dim=input_dim, nclasses=nclasses, sequencelength=args.samplet, dropout=0.4)\n",
    "    model.load(f\"{model_root}/{mode}/{exp}/model.pth\")\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    \n",
    "    return testdataloader, model\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    stats = list()\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    y_preds = list()\n",
    "    ys = list()\n",
    "    ids = list()\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in tqdm(enumerate(dataloader),total=len(dataloader)):\n",
    "            X,y,id = batch\n",
    "            logsoftmax , *_ = model.forward(X.transpose(1,2).cuda())\n",
    "            y_pred = logsoftmax.argmax(dim=1)\n",
    "            ys.append(y.cpu().detach().numpy())\n",
    "            y_preds.append(y_pred.cpu().detach().numpy())\n",
    "            ids.append(id)\n",
    "    model.cpu()\n",
    "    return np.hstack(y_preds), np.vstack(ys)[:,0], np.hstack(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TUM Dataset \n",
    "\n",
    "### 12 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BavarianCropsDataset test partition in holl\n",
      "read 12 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping12.csv/blocks/holl/test\n",
      "loaded 9583 samples\n",
      "Dataset ../data/BavarianCrops. region holl. partition test. X:9583x(144, 13), y:(9583,) with 12 classes\n",
      "Initializing BavarianCropsDataset test partition in nowa\n",
      "read 12 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping12.csv/blocks/nowa/test\n",
      "loaded 3547 samples\n",
      "Dataset ../data/BavarianCrops. region nowa. partition test. X:3547x(287, 13), y:(3547,) with 12 classes\n",
      "Initializing BavarianCropsDataset test partition in krum\n",
      "read 12 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping12.csv/blocks/krum/test\n",
      "loaded 4278 samples\n",
      "Dataset ../data/BavarianCrops. region krum. partition test. X:4278x(143, 13), y:(4278,) with 12 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in holl\n",
      "read 12 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping12.csv/blocks/holl/trainvalid\n",
      "loaded 24767 samples\n",
      "Dataset ../data/BavarianCrops. region holl. partition trainvalid. X:24767x(71, 13), y:(24767,) with 12 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in nowa\n",
      "read 12 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping12.csv/blocks/nowa/trainvalid\n",
      "loaded 8425 samples\n",
      "Dataset ../data/BavarianCrops. region nowa. partition trainvalid. X:8425x(289, 13), y:(8425,) with 12 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in krum\n",
      "read 12 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping12.csv/blocks/krum/trainvalid\n",
      "loaded 25083 samples\n",
      "Dataset ../data/BavarianCrops. region krum. partition trainvalid. X:25083x(71, 13), y:(25083,) with 12 classes\n",
      "setting random seed to 0\n",
      "loading model from ../models/duplo/12classes/isprs_tum_duplo/model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marc/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72426847b18e4073a8821a4c76e40cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=68), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.37      0.44       581\n",
      "           1       0.95      0.97      0.96     10878\n",
      "           2       0.59      0.84      0.69       995\n",
      "           3       0.93      0.96      0.95      1917\n",
      "           4       0.00      0.00      0.00        56\n",
      "           5       0.50      0.02      0.04        52\n",
      "           6       0.00      0.00      0.00       104\n",
      "           7       0.68      0.74      0.71       777\n",
      "           8       0.77      0.83      0.80      1017\n",
      "           9       0.57      0.28      0.37       275\n",
      "          10       0.48      0.17      0.26       499\n",
      "          11       0.96      0.82      0.89       257\n",
      "\n",
      "    accuracy                           0.87     17408\n",
      "   macro avg       0.58      0.50      0.51     17408\n",
      "weighted avg       0.86      0.87      0.86     17408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marc/miniconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marc/miniconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/marc/miniconda3/envs/pytorch/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8741383272058824,\n",
       " 'kappa': 0.7815129422964229,\n",
       " 'f1_micro': 0.8741383272058825,\n",
       " 'f1_macro': 0.5078856649252542,\n",
       " 'f1_weighted': 0.8609462493356634,\n",
       " 'recall_micro': 0.8741383272058824,\n",
       " 'recall_macro': 0.5001654501970126,\n",
       " 'recall_weighted': 0.8741383272058824,\n",
       " 'precision_micro': 0.8741383272058824,\n",
       " 'precision_macro': 0.5812256570424775,\n",
       " 'precision_weighted': 0.8591904981624588}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdataloader, model = setup(\"BavarianCrops\",\"12classes\")\n",
    "y_pred, y, ids = evaluate(model, testdataloader)\n",
    "print(sklearn.metrics.classification_report(y,y_pred))\n",
    "metrics(y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BavarianCropsDataset test partition in holl\n",
      "read 23 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping23.csv/blocks/holl/test\n",
      "loaded 9792 samples\n",
      "Dataset ../data/BavarianCrops. region holl. partition test. X:9792x(144, 13), y:(9792,) with 23 classes\n",
      "Initializing BavarianCropsDataset test partition in nowa\n",
      "read 23 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping23.csv/blocks/nowa/test\n",
      "loaded 3572 samples\n",
      "Dataset ../data/BavarianCrops. region nowa. partition test. X:3572x(287, 13), y:(3572,) with 23 classes\n",
      "Initializing BavarianCropsDataset test partition in krum\n",
      "read 23 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping23.csv/blocks/krum/test\n",
      "loaded 4306 samples\n",
      "Dataset ../data/BavarianCrops. region krum. partition test. X:4306x(143, 13), y:(4306,) with 23 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in holl\n",
      "read 23 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping23.csv/blocks/holl/trainvalid\n",
      "loaded 25308 samples\n",
      "Dataset ../data/BavarianCrops. region holl. partition trainvalid. X:25308x(71, 13), y:(25308,) with 23 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in nowa\n",
      "read 23 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping23.csv/blocks/nowa/trainvalid\n",
      "loaded 8488 samples\n",
      "Dataset ../data/BavarianCrops. region nowa. partition trainvalid. X:8488x(289, 13), y:(8488,) with 23 classes\n",
      "Initializing BavarianCropsDataset trainvalid partition in krum\n",
      "read 23 classes\n",
      "precached dataset files found at ../data/BavarianCrops/npy/classmapping23.csv/blocks/krum/trainvalid\n",
      "loaded 25368 samples\n",
      "Dataset ../data/BavarianCrops. region krum. partition trainvalid. X:25368x(71, 13), y:(25368,) with 23 classes\n",
      "setting random seed to 0\n",
      "loading model from ../models/duplo/23classes/isprs_tum_duplo/model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a9d164c001456bb5ba92d1fcee9f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=70), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.07      0.10       356\n",
      "           1       0.46      0.68      0.55       225\n",
      "           2       0.65      0.29      0.40       882\n",
      "           3       0.00      0.00      0.00       469\n",
      "           4       0.00      0.00      0.00        23\n",
      "           5       0.65      0.78      0.71       995\n",
      "           6       0.92      0.96      0.94      1917\n",
      "           7       0.00      0.00      0.00        56\n",
      "           8       0.50      0.06      0.11        16\n",
      "           9       0.38      0.08      0.14       121\n",
      "          10       0.84      0.97      0.90      9301\n",
      "          11       0.25      0.00      0.01       226\n",
      "          12       0.00      0.00      0.00        52\n",
      "          13       0.27      0.12      0.17       104\n",
      "          14       0.60      0.84      0.70       777\n",
      "          15       0.74      0.82      0.78      1017\n",
      "          16       0.53      0.38      0.44       248\n",
      "          17       0.46      0.09      0.15       466\n",
      "          18       0.84      0.36      0.50        90\n",
      "          19       0.17      0.42      0.24        12\n",
      "          20       0.93      0.86      0.89       257\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.60      0.09      0.16        33\n",
      "\n",
      "    accuracy                           0.79     17670\n",
      "   macro avg       0.43      0.34      0.34     17670\n",
      "weighted avg       0.74      0.79      0.75     17670\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7900396151669496,\n",
       " 'kappa': 0.6795626476440702,\n",
       " 'f1_micro': 0.7900396151669495,\n",
       " 'f1_macro': 0.342844877582905,\n",
       " 'f1_weighted': 0.747589372509714,\n",
       " 'recall_micro': 0.7900396151669496,\n",
       " 'recall_macro': 0.3417897309311548,\n",
       " 'recall_weighted': 0.7900396151669496,\n",
       " 'precision_micro': 0.7900396151669496,\n",
       " 'precision_macro': 0.4343676608558107,\n",
       " 'precision_weighted': 0.73517078259069}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdataloader, model = setup(\"BavarianCrops\",\"23classes\")\n",
    "y_pred, y, ids = evaluate(model, testdataloader)\n",
    "print(sklearn.metrics.classification_report(y,y_pred))\n",
    "metrics(y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAF Dataset\n",
    "\n",
    "### 12 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving npy arrays to ../data/GAFdataset/npy/holl\n",
      "features='optical': selecting 10 optical features from all 18 features\n",
      "gaf classes [6, 7, 13, 15, 17, 21, 22, 23, 34, 36, 37, 45, 60, 102, 105] not in classmapping ../data/BavarianCrops/classmapping12.csv. ignoring 190 examples (2.64% of dataset)\n",
      "Dataset ../data/GAFdataset/test_train_holl.h5. region holl. partition test. X:(7018, 23, 10), y:(7018,) with 12 classes\n",
      "saving npy arrays to ../data/GAFdataset/npy/nowa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/datasets/GAFDataset.py:117: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  self.classweights = 1 / self.hist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features='optical': selecting 10 optical features from all 18 features\n",
      "gaf classes [13] not in classmapping ../data/BavarianCrops/classmapping12.csv. ignoring 1 examples (0.04% of dataset)\n",
      "Dataset ../data/GAFdataset/test_train_nowa.h5. region nowa. partition test. X:(2659, 23, 10), y:(2659,) with 12 classes\n",
      "saving npy arrays to ../data/GAFdataset/npy/krum\n",
      "features='optical': selecting 10 optical features from all 18 features\n",
      "gaf classes [5, 6, 7, 13, 15, 22, 34, 36, 37, 42, 47, 50, 60, 83, 91] not in classmapping ../data/BavarianCrops/classmapping12.csv. ignoring 88 examples (2.33% of dataset)\n",
      "Dataset ../data/GAFdataset/test_train_krum.h5. region krum. partition test. X:(3685, 23, 10), y:(3685,) with 12 classes\n",
      "saving npy arrays to ../data/GAFdataset/npy/holl\n",
      "features='optical': selecting 10 optical features from all 18 features\n",
      "gaf classes [6, 7, 13, 15, 17, 21, 22, 23, 34, 36, 37, 45, 60, 102, 105] not in classmapping ../data/BavarianCrops/classmapping12.csv. ignoring 410 examples (2.62% of dataset)\n",
      "Dataset ../data/GAFdataset/test_train_holl.h5. region holl. partition train. X:(15242, 23, 10), y:(15242,) with 12 classes\n",
      "saving npy arrays to ../data/GAFdataset/npy/nowa\n",
      "features='optical': selecting 10 optical features from all 18 features\n",
      "gaf classes [13] not in classmapping ../data/BavarianCrops/classmapping12.csv. ignoring 4 examples (0.07% of dataset)\n",
      "Dataset ../data/GAFdataset/test_train_nowa.h5. region nowa. partition train. X:(5782, 23, 10), y:(5782,) with 12 classes\n",
      "saving npy arrays to ../data/GAFdataset/npy/krum\n",
      "features='optical': selecting 10 optical features from all 18 features\n",
      "gaf classes [5, 6, 7, 13, 15, 22, 34, 36, 37, 42, 47, 50, 60, 83, 91] not in classmapping ../data/BavarianCrops/classmapping12.csv. ignoring 339 examples (1.93% of dataset)\n",
      "Dataset ../data/GAFdataset/test_train_krum.h5. region krum. partition train. X:(17267, 23, 10), y:(17267,) with 12 classes\n",
      "setting random seed to 0\n",
      "loading model from ../models/duplo/12classes/isprs_gaf_duplo/model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marc/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a3a2a0daa246a0bb83b607b904049d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=53), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.52      0.65       295\n",
      "           1       0.98      1.00      0.99      7685\n",
      "           2       0.81      0.75      0.78       906\n",
      "           3       0.98      0.99      0.99      1807\n",
      "           4       0.00      0.00      0.00        33\n",
      "           5       0.25      0.49      0.33        41\n",
      "           6       0.39      0.16      0.23        97\n",
      "           7       0.94      0.86      0.90       719\n",
      "           8       0.91      0.90      0.91       871\n",
      "           9       0.65      0.64      0.64       220\n",
      "          10       0.50      0.67      0.57       440\n",
      "          11       0.98      0.98      0.98       248\n",
      "\n",
      "    accuracy                           0.93     13362\n",
      "   macro avg       0.69      0.66      0.66     13362\n",
      "weighted avg       0.93      0.93      0.93     13362\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.927555755126478,\n",
       " 'kappa': 0.8852373005391233,\n",
       " 'f1_micro': 0.9275557551264781,\n",
       " 'f1_macro': 0.6636012897456645,\n",
       " 'f1_weighted': 0.92586176498358,\n",
       " 'recall_micro': 0.927555755126478,\n",
       " 'recall_macro': 0.662902765563483,\n",
       " 'recall_weighted': 0.927555755126478,\n",
       " 'precision_micro': 0.927555755126478,\n",
       " 'precision_macro': 0.688580658590887,\n",
       " 'precision_weighted': 0.9284482810983207}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdataloader, model = setup(\"GAFv2\",\"12classes\")\n",
    "y_pred, y, ids = evaluate(model, testdataloader)\n",
    "print(sklearn.metrics.classification_report(y,y_pred))\n",
    "metrics(y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving npy arrays to ../data/GAFdataset/npy/holl\n",
      "features='optical': selecting 10 optical features from all 18 features\n",
      "gaf classes [6, 17, 21, 22, 23, 34, 45, 60, 102, 105] not in classmapping ../data/BavarianCrops/classmapping23.csv. ignoring 91 examples (1.26% of dataset)\n",
      "Dataset ../data/GAFdataset/test_train_holl.h5. region holl. partition test. X:(7117, 23, 10), y:(7117,) with 23 classes\n",
      "saving npy arrays to ../data/GAFdataset/npy/nowa\n",
      "features='optical': selecting 10 optical features from all 18 features\n",
      "Dataset ../data/GAFdataset/test_train_nowa.h5. region nowa. partition test. X:(2660, 23, 10), y:(2660,) with 23 classes\n",
      "saving npy arrays to ../data/GAFdataset/npy/krum\n",
      "features='optical': selecting 10 optical features from all 18 features\n",
      "gaf classes [5, 6, 22, 34, 42, 47, 50, 60, 83, 91] not in classmapping ../data/BavarianCrops/classmapping23.csv. ignoring 66 examples (1.75% of dataset)\n",
      "Dataset ../data/GAFdataset/test_train_krum.h5. region krum. partition test. X:(3707, 23, 10), y:(3707,) with 23 classes\n",
      "saving npy arrays to ../data/GAFdataset/npy/holl\n",
      "features='optical': selecting 10 optical features from all 18 features\n",
      "gaf classes [6, 17, 21, 22, 23, 34, 45, 60, 102, 105] not in classmapping ../data/BavarianCrops/classmapping23.csv. ignoring 256 examples (1.64% of dataset)\n",
      "Dataset ../data/GAFdataset/test_train_holl.h5. region holl. partition train. X:(15396, 23, 10), y:(15396,) with 23 classes\n",
      "saving npy arrays to ../data/GAFdataset/npy/nowa\n",
      "features='optical': selecting 10 optical features from all 18 features\n",
      "Dataset ../data/GAFdataset/test_train_nowa.h5. region nowa. partition train. X:(5786, 23, 10), y:(5786,) with 23 classes\n",
      "saving npy arrays to ../data/GAFdataset/npy/krum\n",
      "features='optical': selecting 10 optical features from all 18 features\n",
      "gaf classes [5, 6, 22, 34, 42, 47, 50, 60, 83, 91] not in classmapping ../data/BavarianCrops/classmapping23.csv. ignoring 176 examples (1.00% of dataset)\n",
      "Dataset ../data/GAFdataset/test_train_krum.h5. region krum. partition train. X:(17430, 23, 10), y:(17430,) with 23 classes\n",
      "setting random seed to 0\n",
      "loading model from ../models/duplo/23classes/isprs_gaf_duplo/model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c340eae0be7a417da37f25212ae5cb2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=53), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.15      0.23       136\n",
      "           1       0.76      0.83      0.80       159\n",
      "           2       0.56      0.63      0.59       699\n",
      "           3       0.30      0.05      0.09       314\n",
      "           4       0.00      0.00      0.00        21\n",
      "           5       0.77      0.86      0.81       906\n",
      "           6       0.99      0.99      0.99      1807\n",
      "           7       0.44      0.12      0.19        33\n",
      "           8       0.86      0.60      0.71        10\n",
      "           9       1.00      0.80      0.89         5\n",
      "          10       0.91      0.96      0.94      6519\n",
      "          11       0.42      0.14      0.21       153\n",
      "          12       0.23      0.41      0.30        41\n",
      "          13       0.38      0.33      0.35        97\n",
      "          14       0.87      0.93      0.90       719\n",
      "          15       0.87      0.93      0.90       871\n",
      "          16       0.66      0.56      0.61       196\n",
      "          17       0.64      0.37      0.47       412\n",
      "          18       0.72      0.83      0.77        76\n",
      "          19       0.60      0.60      0.60        10\n",
      "          20       0.95      0.99      0.97       248\n",
      "          21       0.15      0.08      0.11        24\n",
      "          22       0.25      0.46      0.33        28\n",
      "\n",
      "    accuracy                           0.86     13484\n",
      "   macro avg       0.60      0.55      0.55     13484\n",
      "weighted avg       0.84      0.86      0.84     13484\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8604271729457135,\n",
       " 'kappa': 0.8058421280433244,\n",
       " 'f1_micro': 0.8604271729457135,\n",
       " 'f1_macro': 0.5536350148048996,\n",
       " 'f1_weighted': 0.8447973512451027,\n",
       " 'recall_micro': 0.8604271729457135,\n",
       " 'recall_macro': 0.54887918927095,\n",
       " 'recall_weighted': 0.8604271729457135,\n",
       " 'precision_micro': 0.8604271729457135,\n",
       " 'precision_macro': 0.6017883560617329,\n",
       " 'precision_weighted': 0.8412960831836521}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdataloader, model = setup(\"GAFv2\",\"23classes\")\n",
    "y_pred, y, ids = evaluate(model, testdataloader)\n",
    "print(sklearn.metrics.classification_report(y,y_pred))\n",
    "metrics(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
